{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import urllib.request\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "import yaml\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from string import Template\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFile = '../pipeline/config.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(configFile, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except:\n",
    "    raise Exception(\"Could not load config file at\", configFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPARQL = 0\n",
    "CSV = 1\n",
    "\n",
    "def sparqlResultToDict(results):\n",
    "    rows = []\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        row = {}\n",
    "        for key in results[\"head\"][\"vars\"]:\n",
    "            if key in result:\n",
    "                row[key] = result[key][\"value\"]\n",
    "            else:\n",
    "                row[key] = None\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def writeData(data):\n",
    "    try:\n",
    "        with open(config['dataFile'], 'w') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['id','image','width','height','documentCoordinates'])\n",
    "            writer.writeheader()\n",
    "            for row in data:\n",
    "                if not 'documentCoordinates' in row:\n",
    "                    row['documentCoordinates'] = None\n",
    "                writer.writerow(row)\n",
    "    except:\n",
    "        raise Exception(\"Could not write to\", config['dataFile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = False\n",
    "if config['mode'] == \"SPARQL\":\n",
    "    mode = SPARQL\n",
    "elif config['mode'] == \"CSV\":\n",
    "    mode  = CSV\n",
    "else:\n",
    "    raise Exception(\"mode not specified or invalid (should be SPARQL or CSV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from input file, if present. This is being done for both CSV and SPARQL mode as the SPARQL results will be cashed in the CSV file and updated when data is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = []\n",
    "try:\n",
    "    with open(config['dataFile'], 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            inputData.append({\n",
    "                \"id\": row['id'],\n",
    "                \"image\": row['image'],\n",
    "                \"width\": row['width'],\n",
    "                \"height\": row['height'],\n",
    "                \"documentCoordinates\": row['documentCoordinates'] if 'documentCoordinates' in row else None\n",
    "            })\n",
    "except:\n",
    "    print(\"No prior input file found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in SPARQL mode, get data from SPARQL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == SPARQL:\n",
    "    if not config['endpoint'] or not config['query']:\n",
    "        raise Exception(\"incomplete configuration for SPARQL mode\")\n",
    "        \n",
    "    sparql = SPARQLWrapper(config['endpoint'], returnFormat=JSON)\n",
    "    sparql.setQuery(config['query'])\n",
    "    try:\n",
    "        ret = sparql.query().convert()\n",
    "    except:\n",
    "        raise Exception(\"Could not execute query against endpoint\", config['endpoint'])\n",
    "    queriedData = sparqlResultToDict(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in SPARQL mode, merge queried data with data stored in CSV file.\n",
    "- add entries that exist in SPARQL result, but not in the CSV file\n",
    "- add width/height information when it is only available in either the CSV file or the SPARQL output (prioritising the SPARQL data)\n",
    "Store merged data in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inputData\n",
    "\n",
    "if mode == SPARQL:\n",
    "    inputDataHash = {}\n",
    "    queriedDataHash = {}\n",
    "\n",
    "    for row in inputData:\n",
    "        inputDataHash[row['id']] = row\n",
    "    for row in queriedData:\n",
    "        queriedDataHash[row['id']] = row\n",
    "\n",
    "    idsInInputData = [d['id'] for d in inputData]\n",
    "    for row in queriedData:\n",
    "        if row['id'] not in idsInInputData:\n",
    "            data.append(row)\n",
    "\n",
    "    for row in data:\n",
    "        if not row['width']:\n",
    "            if row['id'] in queriedDataHash and queriedDataHash[row['id']]['width']:\n",
    "                row['width'] = queriedDataHash[row['id']]['width']\n",
    "            elif row['id'] in inputDataHash and inputDataHash[row['id']]['width']:\n",
    "                row['width'] = inputDataHash[row['id']]['width']\n",
    "        if not row['height']:\n",
    "            if row['id'] in queriedDataHash and queriedDataHash[row['id']]['height']:\n",
    "                row['height'] = queriedDataHash[row['id']]['height']\n",
    "            elif row['id'] in inputDataHash and inputDataHash[row['id']]['width']:\n",
    "                row['height'] = inputDataHash[row['id']]['height']\n",
    "    \n",
    "    writeData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get (missing) image sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the original image size is not specified, call the IIIF Image API to read the size from the JSON rsponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28103/28103 [00:00<00:00, 269716.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(data):\n",
    "    if not row['width'] or not row['height']:\n",
    "        uri = row['image'] + '/info.json'\n",
    "        try:\n",
    "            with urllib.request.urlopen(uri) as url:\n",
    "                manifestData = json.loads(url.read().decode())\n",
    "                \n",
    "        except:\n",
    "            print(\"Could not open\", uri)\n",
    "            next\n",
    "        row['width'] = manifestData['width']\n",
    "        row['height'] = manifestData['height']\n",
    "        writeData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the images that do not yet exist in the image folder. The images will be downloaded resized to a width of 1024 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Path(config['imageDirectory']).mkdir(parents=True, exist_ok=True)\n",
    "except:\n",
    "    raise Exception(\"Could not add/access folder\", config['imageDirectory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Detect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSOImageCropping:\n",
    "    \n",
    "    showImages = False\n",
    "    extension = 50\n",
    "    \n",
    "    METHOD_TRHESH = 0\n",
    "    METHOD_CANNY = 1\n",
    "\n",
    "    SELECT_SQUAREST = 0\n",
    "    SELECT_LARGEST = 1\n",
    "    \n",
    "    def __init__(self, showImages=False):\n",
    "        self.showImages = showImages\n",
    "        \n",
    "    def applyMorphologyClose(self, image):\n",
    "        # Applie a Kernel that \"smears\" the image horizontally\n",
    "        # and slightly downwards. Can help in some instances to\n",
    "        # close gaps between shapes, e.g. text\n",
    "        padding = 15\n",
    "        kernel = np.ones((2,10), np.uint8)\n",
    "        if image[image.shape[0]-padding][padding] > 127:\n",
    "            return cv2.morphologyEx(255-image.copy(), cv2.MORPH_CLOSE, kernel)\n",
    "        else:\n",
    "            return cv2.morphologyEx(image.copy(), cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    def blurImage(self, image, amount=5):\n",
    "        return cv2.blur(image.copy(), (amount, amount))\n",
    "    \n",
    "    def cannyImage(self, image):\n",
    "        return cv2.Canny(image.copy(), 10, 120)\n",
    "    \n",
    "    def displayImage(self, image):\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    def erodeImage(self, image, iterations=5):\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        return cv2.erode(image.copy(), kernel, iterations)\n",
    "        \n",
    "    def extendImage(self, image):\n",
    "        return cv2.copyMakeBorder(image.copy(), self.extension, self.extension, self.extension, self.extension, cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    def makeBW(self, image):\n",
    "        return cv2.cvtColor(image.copy(), cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    def thresholdImage(self, image):   \n",
    "        padding = 5\n",
    "        if image[image.shape[0]-padding][image.shape[1]-padding] > 127:\n",
    "            thresholdMethod = cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU\n",
    "        else:\n",
    "            thresholdMethod = cv2.THRESH_BINARY+cv2.THRESH_OTSU\n",
    "        \n",
    "        ret, thresh = cv2.threshold(image,0,255,thresholdMethod)   \n",
    "        return thresh\n",
    "    \n",
    "    def cropImage(self, image, preprocessMethod=METHOD_TRHESH, selectMethod=SELECT_SQUAREST):\n",
    "        # Extend image to improve recognition of (document) edges that\n",
    "        # are close to the image edge\n",
    "        extendedImage = self.extendImage(image)\n",
    "        \n",
    "        # Convert image to Black and White\n",
    "        grayImage = self.makeBW(extendedImage)\n",
    "        \n",
    "        # Smear or blur image to remove detail and close gaps\n",
    "        morphImage = self.applyMorphologyClose(grayImage)\n",
    "        #blurImage = self.blurImage(morphImage)\n",
    "        \n",
    "        # Binarise image\n",
    "        if preprocessMethod == self.METHOD_CANNY:\n",
    "            thresh = self.cannyImage(morphImage)\n",
    "        else:\n",
    "            thresh = self.thresholdImage(morphImage)\n",
    "        \n",
    "        # Detect contours\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # (for debugging) Draw contours on image\n",
    "        contourImage = np.zeros(extendedImage.shape)\n",
    "        cv2.drawContours(contourImage, contours, -1, (0,255,0), 3)\n",
    "            \n",
    "        # Retrieve the areas of the contours and select n largest\n",
    "        areas = [cv2.contourArea(c) for c in contours]\n",
    "        indicesOfLargestContours = [areas.index(x) for x in sorted(areas, reverse=True)[:2]]\n",
    "        \n",
    "        # Pick contour based on selection method, either the largest contour detected\n",
    "        # or the one which is closest in ratio to a square. The ratio method can be useful\n",
    "        # to discard a colour calibration bar which might be detected\n",
    "        if selectMethod == self.SELECT_SQUAREST:\n",
    "            ratios = []\n",
    "            for i in indicesOfLargestContours:\n",
    "                x,y,w,h = cv2.boundingRect(contours[i])\n",
    "                ratios.append(max(w,h)/min(w,h))\n",
    "            indexToPick = np.argmin(ratios)\n",
    "        elif selectMethod == self.SELECT_LARGEST:\n",
    "            indexToPick = 0\n",
    "        \n",
    "        # (for debugging) Draw detected contours\n",
    "        drawThickness = 8\n",
    "        \n",
    "        rectangleImage = extendedImage.copy()\n",
    "        for i in indicesOfLargestContours:\n",
    "            x,y,w,h = cv2.boundingRect(contours[i])\n",
    "            cv2.rectangle(rectangleImage, (x, y) , (x + w, y + h), (0,255,0) ,drawThickness)\n",
    "        \n",
    "        # Retrieve coordinates of selected contour\n",
    "        chosenX, chosenY, chosenW, chosenH = cv2.boundingRect(contours[indicesOfLargestContours[indexToPick]])\n",
    "        \n",
    "        x0 = chosenX\n",
    "        x1 = chosenX + chosenW\n",
    "        y0 = chosenY\n",
    "        y1 = chosenY + chosenH\n",
    "        \n",
    "        # Remove border that has been added in the first step\n",
    "        x0 = max(0, chosenX - self.extension)\n",
    "        y0 = max(0, chosenY - self.extension)\n",
    "        x1 = min(x0 + chosenW, image.shape[1])\n",
    "        y1 = min(y0 + chosenH, image.shape[0])\n",
    "        \n",
    "        # (for debugging) Draw rectangle of selected region\n",
    "        cv2.rectangle(rectangleImage, (chosenX, chosenY), (chosenX + chosenW, chosenY + chosenH), (255,0,0), drawThickness)\n",
    "\n",
    "        croppedImage = image.copy()[y0:y1, x0:x1]\n",
    "        \n",
    "        if self.showImages:\n",
    "            self.displayImage(image)\n",
    "            #self.displayImage(morphImage)\n",
    "            self.displayImage(thresh)\n",
    "            self.displayImage(contourImage)\n",
    "            #self.displayImage(rectangleImage)\n",
    "            self.displayImage(croppedImage)\n",
    "            \n",
    "        return x0, y0, x1-x0, y1-y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 24513/28103 [1:58:05<18:19,  3.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-812808.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24737/28103 [1:59:12<16:19,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815037.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24743/28103 [1:59:14<15:54,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24746/28103 [1:59:14<13:47,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815054.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 24748/28103 [1:59:15<11:35,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815062.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24760/28103 [1:59:18<16:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815093.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 24762/28103 [1:59:18<12:57,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815097.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24765/28103 [1:59:19<12:36,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815102.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24773/28103 [1:59:21<15:47,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815125.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 24832/28103 [1:59:39<15:55,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-815670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 25395/28103 [2:02:29<13:29,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-822350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 25739/28103 [2:04:13<11:13,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-838092.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 25754/28103 [2:04:17<11:50,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-838152.jpg\n",
      "Could not open ../data/images/nb-838155.jpg\n",
      "Could not open ../data/images/nb-838157.jpg\n",
      "Could not open ../data/images/nb-838160.jpg\n",
      "Could not open ../data/images/nb-838162.jpg\n",
      "Could not open ../data/images/nb-838164.jpg\n",
      "Could not open ../data/images/nb-838166.jpg\n",
      "Could not open ../data/images/nb-838168.jpg\n",
      "Could not open ../data/images/nb-838170.jpg\n",
      "Could not open ../data/images/nb-838172.jpg\n",
      "Could not open ../data/images/nb-838174.jpg\n",
      "Could not open ../data/images/nb-838176.jpg\n",
      "Could not open ../data/images/nb-838178.jpg\n",
      "Could not open ../data/images/nb-838180.jpg\n",
      "Could not open ../data/images/nb-838182.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 25879/28103 [2:04:50<11:03,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-841831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 25886/28103 [2:04:52<10:10,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-841890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 25958/28103 [2:05:13<10:44,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-861242.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 26034/28103 [2:05:36<11:09,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open ../data/images/nb-870419.jpg\n",
      "Could not open ../data/images/nb-870422.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28103/28103 [2:15:54<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "detector = BSOImageCropping()\n",
    "    \n",
    "for row in tqdm(data):\n",
    "    if not row['documentCoordinates'] or len(row['documentCoordinates']) == 0:\n",
    "        \n",
    "        filename = path.join(config['imageDirectory'], row['id'] + '.jpg')\n",
    "        if isfile(filename):\n",
    "            image = cv2.imread(filename)\n",
    "            image = image[:,:,::-1]\n",
    "            if not 'zbz' in filename:\n",
    "                x,y,w,h = detector.cropImage(image, selectMethod=BSOImageCropping.SELECT_LARGEST)\n",
    "            else:\n",
    "                x,y,w,h = detector.cropImage(image, selectMethod=BSOImageCropping.SELECT_SQUAREST)\n",
    "\n",
    "            # Upscale to original size\n",
    "            scaleFactor = int(row['width'])/image.shape[1]\n",
    "            row['documentCoordinates'] = \"%d,%d,%d,%d\" % (int( x * scaleFactor),\n",
    "                                                          int( y * scaleFactor),\n",
    "                                                          int( w * scaleFactor),\n",
    "                                                          int( h * scaleFactor))\n",
    "\n",
    "            # Store coordinates in data after every prediction\n",
    "            writeData(data)\n",
    "        else:\n",
    "            print(\"Could not open\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Output as CIDOC-CRM RDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output as a Trig file that can be displayed and edited in the Mirador component of ResearchSpace & Metaphacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = \"\"\"\n",
    "PREFIX Platform: <http://www.metaphacts.com/ontologies/platform#> \n",
    "PREFIX User: <http://www.metaphacts.com/resource/user/> \n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> \n",
    "PREFIX crmdig: <http://www.ics.forth.gr/isl/CRMdig/> \n",
    "PREFIX rso: <http://www.researchspace.org/ontology/> \n",
    "PREFIX prov: <http://www.w3.org/ns/prov#> \n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX ldp: <http://www.w3.org/ns/ldp#> \n",
    "PREFIX crm: <http://www.cidoc-crm.org/cidoc-crm/>\n",
    "\"\"\"\n",
    "\n",
    "static = \"\"\"\n",
    "\n",
    "<https://platform.swissartresearch.net/imageRegions> {\n",
    "    <https://resource.swissartresearch.net/type/imageRegion> a crm:E55_Type ;\n",
    "    rdfs:label \"Image Region\" ;\n",
    "    crm:P3_has_note \"A region defining the visual image represented within a digital image. For example, the region denotes the visual item that is reproduced on a document which is photographed.\".\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "regionTemplate = Template('''<$uri/container/context> {\n",
    "  Platform:formContainer ldp:contains <$uri/container> .\n",
    "  \n",
    "  <$uri>\n",
    "    a crmdig:D35_Area, rso:EX_Digital_Image_Region;\n",
    "    crmdig:L49_is_primary_area_of <$iiifImage>;\n",
    "    crm:P33_used_specific_technique <https://github.com/swiss-art-research-net/bso-image-segmentation> ;\n",
    "    rso:boundingBox \"xywh=$x,$y,$w,$h\";\n",
    "    rso:displayLabel \"image\";\n",
    "    rso:viewport \"xywh=0,0,0,0\";\n",
    "    rdf:value \"<svg xmlns='http://www.w3.org/2000/svg'><path xmlns=\\\\\"http://www.w3.org/2000/svg\\\\\" d=\\\\\"M${x0},${y0}l${halfW},0l0,0l${halfW},0l 0,${halfH}l 0,${halfH}l -${halfW},0l -${halfW},0l 0,-${halfH}z\\\\\" data-paper-data=\\\\\"{&quot;defaultStrokeValue&quot;:1,&quot;editStrokeValue&quot;:5,&quot;currentStrokeValue&quot;:1,&quot;rotation&quot;:0,&quot;deleteIcon&quot;:null,&quot;rotationIcon&quot;:null,&quot;group&quot;:null,&quot;editable&quot;:true,&quot;annotation&quot;:null}\\\\\" id=\\\\\"rectangle_e880ad36-1fef-4ce3-835d-716ba7db628a\\\\\" fill-opacity=\\\\\"0\\\\\" fill=\\\\\"#00bfff\\\\\" fill-rule=\\\\\"nonzero\\\\\" stroke=\\\\\"#00bfff\\\\\" stroke-width=\\\\\"4.04992\\\\\" stroke-linecap=\\\\\"butt\\\\\" stroke-linejoin=\\\\\"miter\\\\\" stroke-miterlimit=\\\\\"10\\\\\" stroke-dasharray=\\\\\"\\\\\" stroke-dashoffset=\\\\\"0\\\\\" font-family=\\\\\"none\\\\\" font-weight=\\\\\"none\\\\\" font-size=\\\\\"none\\\\\" text-anchor=\\\\\"none\\\\\" style=\\\\\"mix-blend-mode: normal\\\\\"/></svg>\" .\n",
    "  \n",
    "  <$uri/container>\n",
    "    a ldp:Resource, prov:Entity;\n",
    "    prov:generatedAtTime \"$dateTime\"^^xsd:dateTime;\n",
    "    prov:wasAttributedTo User:admin .\n",
    "}\n",
    "\n",
    "<https://platform.swissartresearch.net/imageRegions> {\n",
    "    <$uri> crm:P2_has_type <https://resource.swissartresearch.net/type/imageRegion> .\n",
    "}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28103/28103 [00:01<00:00, 19079.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not detect coordinates in 32 images:\n",
      "nb-812808\n",
      "nb-815037\n",
      "nb-815050\n",
      "nb-815054\n",
      "nb-815062\n",
      "nb-815093\n",
      "nb-815097\n",
      "nb-815102\n",
      "nb-815125\n",
      "nb-815670\n",
      "nb-822350\n",
      "nb-838092\n",
      "nb-838152\n",
      "nb-838155\n",
      "nb-838157\n",
      "nb-838160\n",
      "nb-838162\n",
      "nb-838164\n",
      "nb-838166\n",
      "nb-838168\n",
      "nb-838170\n",
      "nb-838172\n",
      "nb-838174\n",
      "nb-838176\n",
      "nb-838178\n",
      "nb-838180\n",
      "nb-838182\n",
      "nb-841831\n",
      "nb-841890\n",
      "nb-861242\n",
      "nb-870419\n",
      "nb-870422\n"
     ]
    }
   ],
   "source": [
    "dateTime = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S+00:00z\")\n",
    "\n",
    "output = namespaces + static\n",
    "\n",
    "missingDocumentCoordinates = []\n",
    "\n",
    "for row in tqdm(data):\n",
    "    if row['documentCoordinates'] is None:\n",
    "        missingDocumentCoordinates.append(row)\n",
    "        continue\n",
    "        \n",
    "    docCoords = row['documentCoordinates'].split(',')\n",
    "    \n",
    "    if len(docCoords) < 4:\n",
    "        missingDocumentCoordinates.append(row)\n",
    "        continue\n",
    "\n",
    "    x = int(docCoords[0])\n",
    "    y = int(docCoords[1])\n",
    "    w = int(docCoords[2])\n",
    "    h = int(docCoords[3])\n",
    "\n",
    "    edges = {\n",
    "        \"topLeft\": (x, y),\n",
    "        \"topRight\": (x + w, y),\n",
    "        \"bottomRight\": (x + w, y + h),\n",
    "        \"bottomLeft\": (x, y + h)\n",
    "    }\n",
    "    iiifImage = row['image']\n",
    "    identifier = str(uuid.uuid3(uuid.NAMESPACE_DNS, iiifImage))\n",
    "    uri = \"https://resource.swissartresearch.net/digitalobject/\" + identifier\n",
    "    x0 = edges['topLeft'][0]\n",
    "    y0 = edges['topLeft'][1]\n",
    "    x1 = edges['bottomRight'][0]\n",
    "    y1 = edges['bottomRight'][1]\n",
    "    x = x0\n",
    "    y = y0\n",
    "    w = x1 - x0\n",
    "    h = y1 - y0\n",
    "    output += regionTemplate.substitute(\n",
    "        uri=uri,\n",
    "        iiifImage=iiifImage,\n",
    "        x=int(x),\n",
    "        y=int(y),\n",
    "        w=int(w),\n",
    "        h=int(h),\n",
    "        x0=x0,\n",
    "        y0=y0,\n",
    "        halfW=float(w/2),\n",
    "        halfH=float(h/2),\n",
    "        dateTime=dateTime\n",
    "    )\n",
    "\n",
    "# Write summary of missing corodinates\n",
    "if len(missingDocumentCoordinates) > 0:\n",
    "    print(\"Could not detect coordinates in %d images:\" % len(missingDocumentCoordinates))\n",
    "    print('\\n'.join([d['id'] for d in missingDocumentCoordinates]))\n",
    "    \n",
    "filename = path.join(config['trigFile'])\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
