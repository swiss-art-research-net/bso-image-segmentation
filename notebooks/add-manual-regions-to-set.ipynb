{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e4e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import yaml\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85774c22",
   "metadata": {},
   "source": [
    "Path to JSON file containing classifications, created with [RunwayML](https://runwayml.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b87539",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileRunway = '../data/Annotation Group - Images and Colour Bars for BSO Examples.json'\n",
    "outputFile = '../data/manualAnnotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7f529",
   "metadata": {},
   "source": [
    "Path to JSON file for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc92d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "configFile = '../pipeline/config.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c0fc1",
   "metadata": {},
   "source": [
    "Load image categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438d7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(inputFileRunway, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db32e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCategory = [d for d in data['categories'] if d['name'] == 'Image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eac0e5",
   "metadata": {},
   "source": [
    "We reuse some of the configuration from the pipeline. Specifically the SPARQL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394f1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(configFile, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except:\n",
    "    raise Exception(\"Could not load config file at\", configFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531f13a",
   "metadata": {},
   "source": [
    "### Define helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e54c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparqlResultToDict(results):\n",
    "    rows = []\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        row = {}\n",
    "        for key in results[\"head\"][\"vars\"]:\n",
    "            if key in result:\n",
    "                row[key] = result[key][\"value\"]\n",
    "            else:\n",
    "                row[key] = None\n",
    "        rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a534e",
   "metadata": {},
   "source": [
    "## Retrieve manually defined regions from SPARL endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65517157",
   "metadata": {},
   "source": [
    "The automatically created image regions contain the statement `?region crm:P33_used_specific_technique <https://github.com/swiss-art-research-net/bso-image-segmentation>`. We can discriminate between manually and automatically created regions by looking at regions where this statement is absent, but the statement `?region crm:P2_has_type <https://resource.swissartresearch.net/type/imageRegion>` (in the named graph `<https://platform.swissartresearch.net/imageRegions>`) is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c058eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX crm: <http://www.cidoc-crm.org/cidoc-crm/>\n",
    "PREFIX crmdig: <http://www.ics.forth.gr/isl/CRMdig/>\n",
    "PREFIX la: <https://linked.art/ns/terms/>\n",
    "PREFIX type: <https://resource.swissartresearch.net/type/>\n",
    "PREFIX rso: <http://www.researchspace.org/ontology/>\n",
    "SELECT ?region ?coordinates ?image ?artwork ?id WHERE {\n",
    "    ?region a crmdig:D35_Area ;\n",
    "        crm:P2_has_type type:imageRegion ;\n",
    "        crmdig:L49_is_primary_area_of ?image ;\n",
    "        rso:boundingBox ?bbox .\n",
    "    ?artwork crm:P128_carries/la:digitally_shown_by/la:digitally_available_via/la:access_point ?image .\n",
    "    FILTER NOT EXISTS {\n",
    "        ?region crm:P33_used_specific_technique <https://github.com/swiss-art-research-net/bso-image-segmentation> .\n",
    "    }\n",
    "    BIND(STRAFTER(STR(?artwork), '/artwork/') as ?id)\n",
    "    BIND(STRAFTER(?bbox, 'xywh=') as ?coordinates)\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e62fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(config['endpoint'], returnFormat=JSON)\n",
    "sparql.setQuery(query)\n",
    "try:\n",
    "    ret = sparql.query().convert()\n",
    "except:\n",
    "    raise Exception(\"Could not execute query against endpoint\", config['endpoint'])\n",
    "manuallyDefinedRegions = sparqlResultToDict(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f52c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 manually defined regions\n"
     ]
    }
   ],
   "source": [
    "print(\"Found\", len(manuallyDefinedRegions), \"manually defined regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e90330",
   "metadata": {},
   "source": [
    "## Get image sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf095d",
   "metadata": {},
   "source": [
    "The training data is defined using relative coordinates. In order to calculate the relative coordinates of the regions from the absolute ones stored in the database, we need to know the original sizes of the images. As part of the data pipeline, image sizes are retrieved from the IIIF manifests and stored in the data CSV. We can hence retrieve the sizes from the CSV where available. Where they are not available, we need to query the IIIF manifest via the URL of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa0dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineData = []\n",
    "pipelineDataIndex = {}\n",
    "with open(config['dataFile'], 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        pipelineData.append(row)\n",
    "        pipelineDataIndex[row['id']] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302d7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in manuallyDefinedRegions:\n",
    "    if region['id'] in pipelineDataIndex.keys():\n",
    "        d = pipelineData[pipelineDataIndex[region['id']]]\n",
    "        region['width'] = float(d['width'])\n",
    "        region['height'] = float(d['height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387b9ef",
   "metadata": {},
   "source": [
    "## Convert regions to RunwayML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec632842",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for region in manuallyDefinedRegions:\n",
    "    filename = region['id'] + '.jpg'\n",
    "    coordinates = region['coordinates'].split(',')\n",
    "    coordinates[0] = float(coordinates[0]) / region['width']\n",
    "    coordinates[1] = float(coordinates[1]) / region['height']\n",
    "    coordinates[2] = float(coordinates[2]) / region['width']\n",
    "    coordinates[3] = float(coordinates[3]) / region['height']\n",
    "    files[filename] = [{\n",
    "        \"type\": \"BOUNDING_BOX\",\n",
    "        \"categoryId\": imageCategory['id'],\n",
    "        \"boundingBox\": coordinates\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71acb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"categories\" : data['categories'],\n",
    "    \"files\": files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputFile, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfa5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
